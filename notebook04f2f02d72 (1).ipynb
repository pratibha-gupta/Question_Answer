{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d = pd.read_csv(\"/kaggle/input/uttarakhand/Uttarakhand.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import BertForQuestionAnswering, BertTokenizer\n\nmodel = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\ntokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def answer_question(question, answer_text):\n    '''\n    This function will take a question_text string and an answer_text string (which contains the\n    answer), and identifies the words within the `answer_text` that are the\n    answer. And then print them out.\n    '''\n    # ======== Tokenizing ========\n    # Tokening the text string.\n    # Apply the tokenizer to the input text, treating them as a text-pair.\n    input_ids = tokenizer.encode(question, answer_text)\n\n    # Report how long the input sequence is.\n    #print('Query has {:,} tokens.\\n'.format(len(input_ids)))\n\n    # ======== Set Segment IDs ========\n    # Search the input_ids for the first instance of the `[SEP]` token.\n    sep_index = input_ids.index(tokenizer.sep_token_id)\n\n    # The number of segment A tokens includes the [SEP] token istelf.\n    num_seg_a = sep_index + 1\n\n    # The remainder are segment B.\n    num_seg_b = len(input_ids) - num_seg_a\n\n    # Construct the list of 0s and 1s.\n    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n\n    # There should be a segment_id for every input token.\n    assert len(segment_ids) == len(input_ids)\n\n    # ======== Evaluate ========\n    # Run our example through the model.\n    outputs = model(torch.tensor([input_ids]), # The tokens representing our input text.\n                    token_type_ids=torch.tensor([segment_ids]), # The segment IDs to differentiate question from answer_text\n                    return_dict=True) \n\n    start_scores = outputs.start_logits\n    end_scores = outputs.end_logits\n\n    # ======== Reconstruct Answer ========\n    # Find the tokens with the highest `start` and `end` scores.\n    answer_start = torch.argmax(start_scores)\n    answer_end = torch.argmax(end_scores)\n\n    # Get the string versions of the input tokens.\n    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n\n    # Start with the first token.\n    answer = tokens[answer_start]\n\n    # Select the remaining answer tokens and join them with whitespace.\n    for i in range(answer_start + 1, answer_end + 1):\n        \n        # If it's a subword token, then recombine it with the previous token.\n        if tokens[i][0:2] == '##':\n            answer += tokens[i][2:]\n        # Otherwise, add a space then the token.\n        else:\n            answer += ' ' + tokens[i]\n    \n    answer = answer.replace('[CLS]','')\n    # A very un-professional way to deal with the [CLS] token\n    # which was being returned upon not finding the proper answer in the part of\n    # the dataset during the iteration\n    print('Answer: \"' + answer + '\"')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '/kaggle/input/uttarakhand/Uttarakhand.csv'\n# import pandas library\nimport pandas as pd\nimport re\n\n#function to remove emojis and other possible icons\ndef deEmojify(text):\n    regrex_pattern = re.compile(pattern = \"[\"\n        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           \"]+\", flags = re.UNICODE)\n    return regrex_pattern.sub(r'',text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing csv file of uttarakhan dataset\nimport csv\ndata = ''\n\nwith open(path, 'r') as file:\n    reader = csv.reader(file)\n    for row in reader:\n        deEmojifiedText = deEmojify(str(row[0]))\n        data+=deEmojifiedText+'. '\n\nprint(row)\nprint(len(data))\nprint(data[:100])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# wrapping all the text.\nimport textwrap\n\nwrapper = textwrap.TextWrapper(width=80) \nprint(wrapper.fill(data[1701:3300]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Trying some questions to answer them.\nquestion = \"What is the helpline number?\"\nfor i in range(0,10):\n  answer_question(question, data[(i*1500):((i+1)*1500)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"question = \"what happened in uttarakhand?\"\nfor i in range(0,10):\n  answer_question(question, data[(i*1500):((i+1)*1500)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"question = \"how much water level rose in rishikesh?\"\nfor i in range(0,10):\n  answer_question(question, data[(i*1500):((i+1)*1500)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"question = \"what is the emergency helpline number?\"\nfor i in range(0,10):\n  answer_question(question, data[(i*1500):((i+1)*1500)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"question = \"How many army units were deployed?\"\nfor i in range(0,10):\n  answer_question(question, data[(i*1500):((i+1)*1500)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"question = \"How many people are affected?\"\nfor i in range(0,10):\n  answer_question(question, data[(i*1600):((i+1)*1600)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}